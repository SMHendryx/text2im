{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_quick_start.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SMHendryx/text2im/blob/main/text2im.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XHd5ExbUIUg"
      },
      "source": [
        "# OpenAI's Text2Image with GLIDE & Diffusion-Based Generate Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzsiN3l_Vy1p",
        "outputId": "6da9f92c-b23a-4dac-c8f8-70a70db874ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (663.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1 MB 1.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.2.0+cu92) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.4.0+cu92) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.2.0+cu92 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.2.0+cu92 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF1P_cRoWpvM"
      },
      "source": [
        "Note: We will be using the latest stable version of PyTorch so be sure to run the command above to install the latest version of PyTorch, which as the time of this tutorial was 1.2.0. We PyTorch belowing using the `torch` module. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su0COdCqT2Wk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXCYmmjyVRq5",
        "outputId": "520a439b-c4fc-4bce-c13a-7ef5b381e10f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.0+cu92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this line in Colab to install the package if it is\n",
        "# not already installed.\n",
        "!pip install git+https://github.com/openai/glide-text2im"
      ],
      "metadata": {
        "id": "4RwosOJRdCQW",
        "outputId": "aaae636a-a8b2-43b9-df10-d8d4081bfd8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/glide-text2im\n",
            "  Cloning https://github.com/openai/glide-text2im to /tmp/pip-req-build-892nvp_j\n",
            "  Running command git clone -q https://github.com/openai/glide-text2im /tmp/pip-req-build-892nvp_j\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (21.2.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (1.2.0+cu92)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (4.62.3)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from glide-text2im==0.0.0) (2019.12.20)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->glide-text2im==0.0.0) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->glide-text2im==0.0.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->glide-text2im==0.0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->glide-text2im==0.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->glide-text2im==0.0.0) (3.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->glide-text2im==0.0.0) (1.19.5)\n",
            "Building wheels for collected packages: glide-text2im, ftfy\n",
            "  Building wheel for glide-text2im (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glide-text2im: filename=glide_text2im-0.0.0-py3-none-any.whl size=1953654 sha256=3d6f0176efd530d8a04c8341f2b9e72830c5cbe8928f30446c8537474bfce303\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zmkswukk/wheels/b4/36/07/46711fd6462da277046c6720504e61546b6e32adc0293abc96\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=1a09096f9f70e2fc21c917ecf019b14e51424a224ef671de7aa942b72169539a\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built glide-text2im ftfy\n",
            "Installing collected packages: ftfy, glide-text2im\n",
            "Successfully installed ftfy-6.0.3 glide-text2im-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler\n",
        ")\n"
      ],
      "metadata": {
        "id": "bIfb2rf8dEK2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This notebook supports both CPU and GPU.\n",
        "# On CPU, generating one sample may take on the order of 20 minutes.\n",
        "# On a GPU, it should be under a minute.\n",
        "\n",
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "MK7horEedJwG",
        "outputId": "d796e037-f801-4032-f420-6ab5fddb180f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create base model.\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = '100' # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "model.load_state_dict(load_checkpoint('base', device))\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ],
      "metadata": {
        "id": "OrCipGE3dLn-",
        "outputId": "01521cf3-a2eb-4b05-a671-38d323b1d33b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5e4be255dc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_fp16'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhas_cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestep_respacing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'100'\u001b[0m \u001b[0;31m# use 100 diffusion steps for fast sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiffusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_and_diffusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/glide_text2im/model_creation.py\u001b[0m in \u001b[0;36mcreate_model_and_diffusion\u001b[0;34m(image_size, num_channels, num_res_blocks, channel_mult, num_heads, num_head_channels, num_heads_upsample, attention_resolutions, dropout, text_ctx, xf_width, xf_layers, xf_heads, xf_final_ln, xf_padding, diffusion_steps, noise_schedule, timestep_respacing, use_scale_shift_norm, resblock_updown, use_fp16, cache_text_emb, inpaint, super_res)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mcache_text_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_text_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0minpaint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minpaint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msuper_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuper_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m     diffusion = create_gaussian_diffusion(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/glide_text2im/model_creation.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(image_size, num_channels, num_res_blocks, channel_mult, attention_resolutions, num_heads, num_head_channels, num_heads_upsample, use_scale_shift_norm, dropout, text_ctx, xf_width, xf_layers, xf_heads, xf_final_ln, xf_padding, resblock_updown, use_fp16, cache_text_emb, inpaint, super_res)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0muse_scale_shift_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_scale_shift_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mresblock_updown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresblock_updown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mcache_text_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_text_emb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/glide_text2im/text2im_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text_ctx, xf_width, xf_layers, xf_heads, xf_final_ln, tokenizer, cache_text_emb, xf_ar, xf_padding, share_unemb, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxf_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxf_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             self.transformer = Transformer(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/glide_text2im/unet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, model_channels, out_channels, num_res_blocks, attention_resolutions, dropout, channel_mult, conv_resample, dims, num_classes, use_checkpoint, use_fp16, num_heads, num_head_channels, num_heads_upsample, use_scale_shift_norm, resblock_updown, encoder_channels)\u001b[0m\n\u001b[1;32m    357\u001b[0m         self.time_embed = nn.Sequential(\n\u001b[1;32m    358\u001b[0m             \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSiLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_embed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'SiLU'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IUDkNSBVdRBO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}